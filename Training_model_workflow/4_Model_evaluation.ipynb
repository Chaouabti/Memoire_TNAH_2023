{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aac7f8d-f982-4ac8-835c-fd4cbb383f78",
   "metadata": {},
   "source": [
    "# Correction from Label Studio and Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601803b8-ff63-49ce-8ed0-94eea362e577",
   "metadata": {},
   "source": [
    "This notebook SHOULD NOT be launched until any corrections have been made in Label Studio.\n",
    "The purpose of the various functions is to be able to extract the data to be analysed after training in order to assess the robustness of the model.\n",
    "\n",
    "**Warning 1**\n",
    "The requirement is to use, or create, a Label Studio account: (https://labelstud.io/guide/install.html) and to have followed the workflow of the previous notebooks (Download_from_manifest, Data_preparation_for_training, Train_and_Detect_YOLOv8.ipynb) or at least to have created similar files.\n",
    "\n",
    "**Warning 2**\n",
    "    The export format for corrections from Label Studio MUST be csv ONLY.\n",
    "    Label Studio's YOLO export format does not allow you to keep the names of the images as they were imported: \n",
    "    in the context of this workflow, these are the URLs of the images from which this script can retrieve the name of the \n",
    "    image and generate .txt files with the same name as the image (thus allowing you to use this new data for a new training session).\n",
    "\n",
    "**Warning 3**\n",
    "It is essential to complete the \"Labeling Interface\" by specifying strictly the same class names \n",
    "(case, special characters, etc.) as those declared in the .json file.\n",
    "\n",
    "**Warning 4**\n",
    "If there is some issue in Label Studio, you can change the labeling results' name from \"predictions\" to \"annotations\",\n",
    "since Label documentation explain that you can't change the bounding box coordinates for prediction, \n",
    "only for detection : https://labelstud.io/guide/predictions.html#Predictions-are-read-only.\n",
    "But I tried and you can change the predicted bounding boxes and export the new data with the changes without any problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ab46e-2d24-49d9-853a-5f6d136ecb5d",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f71f0ae-921e-42db-a318-1061a5c2afe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "from modules.class_names_functions import get_labels, get_class_name, get_class_code\n",
    "from modules.transform_coordinates_functions import from_ls_to_yolo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488719b-87fa-4946-99a7-0bee1799580e",
   "metadata": {},
   "source": [
    "## Get the Label Studio correction in new .txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fac47a6-af7d-4dea-ab15-45cebe69157d",
   "metadata": {},
   "source": [
    "### Generate new txt files with correct bounding boxes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28d723-88bd-4a37-8b6c-1ad8528ca017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_corrected_files(correction_from_ls_csv, dataset_path, yolo_model_folder):\n",
    "    \n",
    "    '''\n",
    "    This function generates new .txt files with the corrections made in Label Studio into a .txt file and should only be run \n",
    "    AFTER the corrections have been made and exported.\n",
    "    \n",
    "    The files generated have the same name as the YOLO results and are sent to a 'correctedLabels' folder in the same \n",
    "    folder as 'labels' so that the data can be used in the following 'Model_evaluation' notebook.\n",
    "    '''\n",
    "    \n",
    "    results_folder = os.path.dirname(correction_from_ls_csv)\n",
    "    \n",
    "    \n",
    "    yolo_result = pd.read_csv(os.path.join(results_folder, os.path.basename(dataset_path) + '.csv'))\n",
    "    ls_reannoted = pd.read_csv(correction_from_ls_csv)\n",
    "    \n",
    "    labels = get_labels(os.path.join(yolo_model_folder, 'labels.txt'))\n",
    "\n",
    "    for _, yolo_row in yolo_result.iterrows():\n",
    "        result_path = str(yolo_row['YOLO_Results_File'])\n",
    "        img_url = str(yolo_row['Url_Image'])\n",
    "\n",
    "        matched_rows = ls_reannoted.loc[ls_reannoted['image'] == img_url]\n",
    "\n",
    "        if not matched_rows.empty:\n",
    "            \n",
    "            corrected_labels_dir = os.path.dirname(result_path).replace('labels', 'correctedLabels')\n",
    "            \n",
    "            if not os.path.exists(corrected_labels_dir):\n",
    "                os.makedirs(corrected_labels_dir)\n",
    "                print(corrected_labels_dir)\n",
    "      \n",
    "            with open(os.path.join(corrected_labels_dir, os.path.basename(result_path)), 'w') as reannotated:\n",
    "                try: \n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        new_coordinates = str(row['label'])\n",
    "                        # print(new_coordinates)\n",
    "                        # print(result_path.replace('.txt', '_correction.txt'))\n",
    "\n",
    "                        try:\n",
    "                            # Normalize coordinates in the list if there is more than one bounding box\n",
    "                            coordinates_list = ast.literal_eval(new_coordinates)\n",
    "                            for coordinates in coordinates_list:\n",
    "                                x, y, width, height = from_ls_to_yolo(coordinates['x'], coordinates['y'], coordinates['width'], coordinates['height'])\n",
    "                                rectanglelabels = get_class_code(coordinates['rectanglelabels'], labels)\n",
    "                                line = f\"{rectanglelabels} {x} {y} {width} {height}\\n\"\n",
    "                                reannotated.write(line)\n",
    "                                # print(img_url)\n",
    "                                # print(line)\n",
    "\n",
    "                        except ValueError:\n",
    "                            reannotated.write('')\n",
    "                            # print(f\"The image {result_path} has no miniature\")\n",
    "                            \n",
    "                except KeyError:\n",
    "                    reannotated.write('')\n",
    "                    # print(f\"The {result_path} image has no miniature\")\n",
    "        else:\n",
    "            print(f\"No corrections made\")\n",
    "            \n",
    "    print(f'The corrected files have been created in {corrected_labels_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41ad14-38fd-4fab-96f8-84b74dca97b1",
   "metadata": {},
   "source": [
    "## Get results in csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893b345c-c591-4a41-a0ea-20f2841e93e5",
   "metadata": {},
   "source": [
    "### Get a list of images used for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d4d76-793c-4428-92d6-fbf901bb7de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img_from_training(yolo_model_folder, dataset_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to return a list of the images that may have been used to train the model.\n",
    "    The will be made from the traindata.txt send in the model folder.\n",
    "\n",
    "    **Warning**\n",
    "    Of course, this script assumes that the training and prediction data have a similar name\n",
    "    and the data were be return in the predict dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    train_data_list = os.path.join(yolo_model_folder, 'dataset_statistics/traindata.txt')\n",
    "    \n",
    "    train_data = []\n",
    "    \n",
    "    with open(train_data_list, 'r') as train_data_file:\n",
    "        for line in train_data_file:\n",
    "            img_path = line.strip()\n",
    "            train_data.append(img_path)\n",
    "    \n",
    "    # print(train_data)\n",
    "      \n",
    "    image_files = [file for file in os.listdir(dataset_path) if file.endswith(('.jpg', '.png'))]\n",
    "    # print(image_files)\n",
    "    \n",
    "    matching_images = [image_name for image_name in train_data if image_name in image_files]\n",
    "   \n",
    "    if matching_images:\n",
    "        print(\"The following images were used to train the model:\")\n",
    "        print(matching_images)\n",
    "        \n",
    "    else:\n",
    "        print(f\"No images in the {dataset_path} folder were used to train the model {os.path.basename(yolo_model_folder)}.\")\n",
    "    \n",
    "    return matching_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dce9be-022f-49f1-b043-e2841fba7fc5",
   "metadata": {},
   "source": [
    "### Calculate IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca6562-b757-4b62-abf2-e570848b7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \n",
    "    \"\"\"\n",
    "    The 'calculate_iou' function is adapted from the 'bb_intersection_over_union' function from \n",
    "    https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/.\n",
    "    The adaptation was necessary because 'bb_intersection_over_union' uses coordinates given in \n",
    "    x_min, y_min, x_max, y_max, whereas the coordinates from YOLOv8 for each prediction are relative \n",
    "    and given in x, y, w, h.\n",
    "    \n",
    "    Parameters:\n",
    "    box1\n",
    "    box2\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convertir les coordonnées (x, y, w, h) en coordonnées (x_min, y_min, x_max, y_max)\n",
    "    box1_x_min = box1[1] - box1[3] / 2\n",
    "    box1_y_min = box1[2] - box1[4] / 2\n",
    "    box1_x_max = box1[1] + box1[3] / 2\n",
    "    box1_y_max = box1[2] + box1[4] / 2\n",
    "    \n",
    "    box2_x_min = box2[1] - box2[3] / 2\n",
    "    box2_y_min = box2[2] - box2[4] / 2\n",
    "    box2_x_max = box2[1] + box2[3] / 2\n",
    "    box2_y_max = box2[2] + box2[4] / 2\n",
    "    \n",
    "    # Calculer les coordonnées (x,y) de l'intersection\n",
    "    x_min = max(box1_x_min, box2_x_min)\n",
    "    y_min = max(box1_y_min, box2_y_min)\n",
    "    x_max = min(box1_x_max, box2_x_max)\n",
    "    y_max = min(box1_y_max, box2_y_max)\n",
    "    \n",
    "    # Calculer l'aire de l'intersection\n",
    "    intersection_area = max(0, x_max - x_min + 1) * max(0, y_max - y_min + 1)\n",
    "\n",
    "    # Calculer l'aire des deux bounding boxes\n",
    "    box1_area = (box1_x_max - box1_x_min + 1) * (box1_y_max - box1_y_min + 1)\n",
    "    box2_area = (box2_x_max - box2_x_min + 1) * (box2_y_max - box2_y_min + 1)\n",
    "    \n",
    "    # Calculer l'Intersection over Union (IoU)\n",
    "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a72d7-cbbd-40cd-b7b1-ca391a8aa2ff",
   "metadata": {},
   "source": [
    "### Get the match boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0eb7d1-a69d-41ee-b422-a20d1f37e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_boxes(predictions, corrected_predictions, threshold):\n",
    "    \n",
    "    \"\"\"\n",
    "    The match_boxes function returns annotated bounding boxes and their predicted matches.\n",
    "    This function also returns false positives (predicted objects for which there is no equivalent in the ground truth) and false negatives (objects present in the ground truth but not detected).\n",
    "    \n",
    "    **Warning**\n",
    "    The 'predictions', 'corrected_predictions' parameters will be automatically filled later.\n",
    "\n",
    "    The threshold parameter, i.e. the threshold below which the detected object will be considered as a false negative (if derived from ground truth) or as a false positive (if derived from prediction).\n",
    "    By default, this threshold is implemented at 0.50, which corresponds to the recommendations of the PASCAL VOC challenge, or at 0.75 (strict detection):\n",
    "    https://cocodataset.org/?ref=jeremyjordan.me#detection-eval.\n",
    "\n",
    "    With a threshold of 0.1, localisation errors are ignored.\n",
    "    \"\"\"\n",
    "    matched_predictions = []\n",
    "    matched_corrections = []\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        prediction_box = prediction.split(\" \")\n",
    "        prediction_box = [float(coord) for coord in prediction_box]\n",
    "        prediction_class = int(prediction_box[0])\n",
    "\n",
    "        best_iou = 0\n",
    "        best_prediction_idx = -1\n",
    "\n",
    "        for i, correction in enumerate(corrected_predictions):\n",
    "            correction_box = correction.split(\" \")\n",
    "            correction_box = [float(coord) for coord in correction_box]\n",
    "            correction_class = int(correction_box[0])\n",
    "\n",
    "            if  prediction_class == correction_class:\n",
    "                iou = calculate_iou(prediction_box, correction_box)\n",
    "\n",
    "                if iou > best_iou and iou >= threshold:\n",
    "                    best_iou = iou\n",
    "                    best_prediction_idx = i\n",
    "\n",
    "        if best_prediction_idx != -1:\n",
    "            matched_predictions.append(prediction)\n",
    "            matched_corrections.append(corrected_predictions[best_prediction_idx])\n",
    "    \n",
    "    false_negatives = [p for p in corrected_predictions if p not in matched_corrections]\n",
    "    false_positives = [a for a in predictions if a not in matched_predictions]\n",
    "\n",
    "\n",
    "    return matched_predictions, matched_corrections, false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f499f0-b1d4-4a7c-afea-ee0ab341cd4a",
   "metadata": {},
   "source": [
    "### Load data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e0c1a-867a-484c-bcba-f7d7213860e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_files(file_paths):\n",
    "    \"\"\"\n",
    "    **Warning**\n",
    "    The 'file_paths' parameter will be automatically filled later.\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                data_list.append(line.strip())\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2313e7c6-d84a-4e7f-b8d5-897b48fd2e60",
   "metadata": {},
   "source": [
    "### Generate the csv with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6084aac-cf39-45a2-97fd-01ae233a27fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_results(correction_from_ls_csv, dataset_path, yolo_model_folder, all_results):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function generates correction results in CSV format. Each annotation is evaluated in TP, FP or FN.\n",
    "    This file is used to calculate the various metrics.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    results_folder = os.path.dirname(correction_from_ls_csv)\n",
    "    labels = get_labels(os.path.join(yolo_model_folder, 'labels.txt'))\n",
    "    \n",
    "    # Get prediction files\n",
    "    prediction_folder = results_folder.replace('results', 'labels')\n",
    "    predictions_files = glob.glob(os.path.join(prediction_folder, '*.txt'))\n",
    "\n",
    "    # Get corrected files\n",
    "    correction_folder = results_folder.replace('results', 'correctedLabels')\n",
    "    corrected_files = glob.glob(os.path.join(correction_folder, '*.txt'))\n",
    "      \n",
    "    if not all_results:\n",
    "        output_file = os.path.join(results_folder, 'results_for_statistics.csv')   # Nom du fichier de sortie       \n",
    "        img_use_for_training = get_img_from_training(yolo_model_folder, dataset_path)\n",
    "        # print(img_use_for_training)\n",
    "\n",
    "        # Exclude the images present in img_use_for_training from predictions_files\n",
    "        predictions_files = [file for file in predictions_files if os.path.basename(file.replace('txt','jpg')) not in img_use_for_training]\n",
    "        corrected_files = [file for file in corrected_files if os.path.basename(file).replace('.txt', '.jpg') not in img_use_for_training]\n",
    "        # print(len(corrected_files))\n",
    "        \n",
    "    else:\n",
    "        output_file = os.path.join(results_folder, 'results_for_evaluation.csv')\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for pred_file in predictions_files:\n",
    "        matching_corr_files = [corr_file for corr_file in corrected_files if os.path.basename(corr_file) == os.path.basename(pred_file)]\n",
    "        # print(matching_corr_files)\n",
    "        \n",
    "        if len(matching_corr_files) == 0:\n",
    "            print(f'No matching file for {pred_file}')\n",
    "            \n",
    "        else:\n",
    "            predictions = load_data_from_files([pred_file])\n",
    "            corrected_predictions= load_data_from_files(matching_corr_files)\n",
    "\n",
    "            matched_predictions, matched_corrections, false_positives, false_negatives = match_boxes(predictions, corrected_predictions, threshold=0.5)\n",
    "            # print(matched_predictions)\n",
    "            \n",
    "            for prediction, correction in zip(matched_predictions, matched_corrections):\n",
    "                iou = calculate_iou([float(coord) for coord in prediction.split(\" \")], [float(coord) for coord in correction.split(\" \")])\n",
    "                box_coordinates = ' '.join(prediction.split(\" \"))\n",
    "\n",
    "                rows.append({'Filename': os.path.basename(pred_file), 'Predicted_results': box_coordinates, 'TP/FP/FN': 'TP', 'classe': get_class_name(prediction[0], labels), 'Corrected_results': correction, 'IoU': iou})\n",
    "\n",
    "            if len(false_positives) != 0:\n",
    "                for false_positive in false_positives:\n",
    "                    rows.append({'Filename': os.path.basename(pred_file), 'Predicted_results': false_positive, 'TP/FP/FN': 'FP', 'classe': get_class_name(false_positive[0], labels), 'Corrected_results': '', 'IoU': ''})\n",
    "\n",
    "            if len(false_negatives) != 0:\n",
    "                for false_negative in false_negatives:\n",
    "                    rows.append({'Filename': os.path.basename(pred_file), 'Predicted_results': '', 'TP/FP/FN': 'FN', 'classe': get_class_name(false_negative[0], labels), 'Corrected_results': false_negative, 'IoU': ''})\n",
    "\n",
    "    # Check for non-matching correction files\n",
    "    for pred_file in predictions_files:\n",
    "        pred_file_name = os.path.basename(pred_file)\n",
    "        matching_corr_files = [corr_file for corr_file in corrected_files if os.path.basename(corr_file) == pred_file_name]\n",
    "\n",
    "        if len(matching_corr_files) == 0:\n",
    "            true_prediction = load_data_from_files([pred_file])\n",
    "            \n",
    "            for predicted_box in true_prediction:\n",
    "                prediction_box = predicted_box.split(\" \")\n",
    "                prediction_box = [float(coord) for coord in prediction_box]\n",
    "                \n",
    "                prediction_class = int(prediction_box[0])\n",
    "                \n",
    "            classe = get_class_name(prediction_class, labels)\n",
    "            box_coordinates = ' '.join(map(str, prediction_box))\n",
    "\n",
    "            rows.append({'Filename': os.path.basename(pred_file), 'Predicted_results': box_coordinates, 'TP/FP/FN': 'TP', 'classe': classe, 'Corrected_results': 'No correction made', 'IoU': ''})\n",
    "\n",
    "    # print(rows)\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    df_sorted = df.sort_values('Filename')\n",
    "    df_sorted.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"The {output_file} file has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a4596-4a6b-4493-8efd-743b2384a681",
   "metadata": {},
   "source": [
    "## Get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ba9d7-abbf-448e-a03b-107eef85455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt_results(correction_from_ls_csv):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates a txt file containing a summary of the data from the previously generated csv.\n",
    "    With ONLY the data without the images used for annotation, for relevant results.\n",
    "    \"\"\"\n",
    "    \n",
    "    results_folder = os.path.dirname(correction_from_ls_csv)\n",
    "    csv_with_results = os.path.join(results_folder, 'results_for_statistics.csv')\n",
    "\n",
    "    df = pd.read_csv(csv_with_results)\n",
    "    output_file = csv_with_results.replace('.csv', '.txt')\n",
    "    \n",
    "    print(output_file)\n",
    "    \n",
    "    # Collect all unique classes present in the DataFrame\n",
    "    all_classes = df['classe'].unique()\n",
    "\n",
    "    # Initialize TP, FP and FN counters for all classes\n",
    "    class_TP = {classe: 0 for classe in all_classes}\n",
    "    class_FP = {classe: 0 for classe in all_classes}\n",
    "    class_FN = {classe: 0 for classe in all_classes}\n",
    "\n",
    "    # Browse DataFrame rows\n",
    "    for _, row in df.iterrows():\n",
    "        classe = row['classe']\n",
    "        # Check TP/FP/FN status for line\n",
    "        if row['TP/FP/FN'] == 'TP':\n",
    "            class_TP[classe] += 1\n",
    "        elif row['TP/FP/FN'] == 'FP':\n",
    "            class_FP[classe] += 1\n",
    "        elif row['TP/FP/FN'] == 'FN':\n",
    "            class_FN[classe] += 1\n",
    "\n",
    "    # Calculate global totals\n",
    "    total_TP = sum(class_TP.values())\n",
    "    total_FP = sum(class_FP.values())\n",
    "    total_FN = sum(class_FN.values())\n",
    "\n",
    "    # Recall computation\n",
    "    recall = total_TP / (total_TP + total_FN) if (total_TP + total_FN) != 0 else 0\n",
    "\n",
    "    # Precision computation\n",
    "    precision = total_TP / (total_TP + total_FP) if(total_TP + total_FP) != 0 else 0\n",
    "\n",
    "    # Calculation of the overall F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "    # Open the file in write mode\n",
    "    with open(output_file, 'w') as file:\n",
    "        # Écrire les résultats globaux\n",
    "        file.write(\"Overall results :\\n\")\n",
    "        file.write(\"Number of TP: {}\\n\".format(total_TP))\n",
    "        file.write(\"Number of FP : {}\\n\".format(total_FP))\n",
    "        file.write(\"Number of FN: {}\\n\".format(total_FN))\n",
    "        file.write(\"\\nRecall (Recall) : {}\\n\".format(recall))\n",
    "        file.write(\"Precision : {}\\n\".format(precision))\n",
    "        file.write(\"Score F1 global : {}\\n\".format(f1_score))\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "        # Write results by class\n",
    "        file.write(\"Results per class :\\n\")\n",
    "        for classe in all_classes:\n",
    "            tp = class_TP[classe]\n",
    "            fp = class_FP[classe]\n",
    "            fn = class_FN[classe]\n",
    "\n",
    "            recall_class = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "            precision_class = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "            f1_score_class = 2 * (precision_class * recall_class) / (precision_class + recall_class) if (precision_class + recall_class) != 0 else 0\n",
    "\n",
    "            file.write(\"Class {}\\n\".format(classe))\n",
    "            file.write(\"Number of TP: {}\\n\".format(tp))\n",
    "            file.write(\"Number of FP : {}\\n\".format(fp))\n",
    "            file.write(\"Number of FN: {}\\n\".format(fn))\n",
    "            file.write(\"Recall (Recall): {}\\n\".format(recall_class))\n",
    "            file.write(\"Precision : {}\\n\".format(precision_class))\n",
    "            file.write(\"Score F1 : {}\\n\".format(f1_score_class))\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "    print(f\"The {output_file} file has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5348ff-9707-4a5e-a48a-0ddaf20cd901",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ef067-0373-4914-8f70-75461c1debc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = 'ABSPATHTOTHEFOLDER' # to be changed, asbolute path to a folder with images only, without annotations.\n",
    "yolo_model_folder = 'ABSPATHTOTHEMODELFOLDER' # to be changed, asbolute path to the folder with the training data\n",
    "\n",
    "# The CSV file from LS must be load in the results folder, i.e the one you create in the previous notebook\n",
    "correction_from_ls_csv = 'ABSPATHTOTHECSVWITHCORRECTIONS'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e1df2f-bfd9-401b-86ae-febb5fd0c1b3",
   "metadata": {},
   "source": [
    "## Generate results from Label Studio with URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a21831-1379-4acd-88b8-908468586f31",
   "metadata": {},
   "source": [
    "### Generate the corrected files in YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a43e3e8-8b98-414e-8279-26b81465c88b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_corrected_files(correction_from_ls_csv, dataset_path, yolo_model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8922939-7803-49d4-8cfa-e524d7121844",
   "metadata": {},
   "source": [
    "### Generate a CSV with the corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc0c483-7322-4d30-9fa1-232dcb27b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_csv_results(correction_from_ls_csv, dataset_path, yolo_model_folder, all_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6e9ae8-1e7e-47e6-b868-aa67150ee981",
   "metadata": {},
   "source": [
    "### Generate the file with metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848544c-9373-4045-9929-e443bcb26ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_txt_results(correction_from_ls_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
